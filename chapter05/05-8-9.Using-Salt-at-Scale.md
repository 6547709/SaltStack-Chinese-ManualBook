# USING SALT AT SCALE - 使用Salt管理大规模的服务器设备
本教程的重点是构建一个Salt基础架构来处理大量的Salt minions。 这将包括调优、拓扑结构和最佳实践。

有关如何安装Salt Master的信息，请访问：[安装saltstack](http://docs.saltstack.com/topics/installation/index.html)

> 注意：本教程适用于大型项目安装场景，虽然使用这些相同的设置并不会让系统受到影响，但在小型安装场景下，为此所增加的复杂性可能不值得。当与minions一起使用时，术语“许多”指的是至少一千个而“少数”则代表至少有500个。为简单起见，本教程将默认使用Salt使用的标准服务端口。

## THE MASTER
Salt Master最常见的问题是：
1. 太多的minions同时在进行认证请求；
2. 太多的minions同时在做重新认证；
3. 太多的minions同时在执行重新连接；
4. 太多的minions同时在返回结果；
5. 资源不足（CPU/HDD）；

前三个都是属于“惊群效应”的问题。 为了缓解这些问题，我们必须将minions配置为在Master负载较重时可以适当地退回。

第四个是由拥有少量硬件资源的masters和ZeroMQ中可能存在的错误引起的。 至少直到今天看起来一直是这样（[问题118651](https://github.com/saltstack/salt/issues/11865)，[问题5948](https://github.com/saltstack/salt/issues/5948)，[邮件主题](https://groups.google.com/forum/#!searchin/salt-users/lots$20of$20minions/salt-users/WxothArv2Do/t12MigMQDFAJ)）

要完全理解每个问题，重要的一点是要了解Salt的工作原理。

简而言之，Salt Master为minions提供两种服务。
- 端口4505上的工作发布者
- 一个开放的端口4506用来接收minins的返回

所有小兵总是在端口4505上连接到发布者，并且如果需要，仅连接到打开的返回端口4506。 在空闲的Master上，端口4505上只有连接。

### TOO MANY MINIONS AUTHING
当Minion服务首次启动时，它将通过端口4505连接到Master的发布者。如果同时启动太多的minions，这可能会导致“惊群效应”。 这可以通过不同时启动太多的minions来避免。

连接本身通常不是罪魁祸首，主要问题的原因更可能是Minion必须对Master进行的身份验证。 如果Master服务器负载过重而无法处理身份验证请求，则会将其超时。 然后Minion将等acceptance_wait_time后重试。 如果设置了acceptance_wait_time_max，那么Minion将在每次后续重试之前通过acceptance_wait_time增加其等待时间，直到达到acceptance_wait_time_max截止。

### TOO MANY MINIONS RE-AUTHING
这很可能发生在Salt部署的测试阶段，当所有Minion密钥都已被接受，但框架正在被测试，并且配置参数在Salt Master的配置文件中经常更改。

Salt Master在某些事件入发生（例如Master重启或删除Minion密钥）时会生成一个新的AES密钥，用于加密其发布的任务。 如果你遇到太多minions对Master服务器做重新认证的问题，你将需要重新校准你的设置以降低此类事件发生的速率，如Master重启或Minion密钥删除（salt-key -d）。

当Master生成新的AES密钥时，不会通知minions，但会在他们收到的下一个pub工作中发现它。 当Minion收到这样的工作后，它将与Master重新认证。 由于Salt选择了在minions端过滤，这意味着所有的minions都会在Master发布的下一个命令上重新认证 - 这可能导致另一个“惊群效应”问题。

这一问题可以通过以下配置进行回避：
```yaml
random_reauth_delay: 60
```
在minions配置文件中配置以更高的值以错开重新auth尝试的数量。 增加此值会增加通过Salt命令访问所有minions所需的时间。

### TOO MANY MINIONS RE-CONNECTING
默认情况下，zmq套接字将每100毫秒重新连接一次，对于某些较大集群规模的安装可能太快了。 这将控制重新建立TCP会话的速度，但与auth加载无关。

要调整minions套接字重新连接尝试，示例配置文件中有一些值（默认值）
```yaml
recon_default: 1000
recon_max: 5000
recon_randomize: True
```
- recon_default: 套接字应使用的默认值，即1000。此值以毫秒为单位。 （1000ms = 1秒）
- recon_max: 套接字在尝试重新连接之前应该用作延迟的最大值，此值以毫秒为单位。 （5000毫秒= 5秒）
- recon_randomize: 启用recon_default和recon_max之间的随机化取值

要将此值配置到现有环境前，必须做出一些决定。
1. 在minions在线并可以通过Salt访问到之前，可以等待多长时间？
2. 在没有未性syn flood的情况下，Master可以处理多少次的重新连接？

这些问题一般无法有明确的答案。 他们的答案取决于硬件和管理员的要求。

这是一个示例场景，目标是让所有minions在Salt Master服务重启时在60秒的时间范围内重新建立起连接。
```yaml
recon_default: 1000
recon_max: 59000
recon_randomize: True
```
每个Minion将在'recon_default'和'recon_default + recon_max'之间随机选择一个重新连接值，在此示例中意味着在1000ms和60000ms之间（或在1到60秒之间）。 每次尝试重新连接后，继续生成的随机值将加倍（ZeroMQ默认行为）。

假设生成的随机值是11秒（或11000ms）。
```
reconnect 1: wait 11 seconds
reconnect 2: wait 22 seconds
reconnect 3: wait 33 seconds
reconnect 4: wait 44 seconds
reconnect 5: wait 55 seconds
reconnect 6: wait time is bigger than 60 seconds (recon_default + recon_max)
reconnect 7: wait 11 seconds
reconnect 8: wait 22 seconds
reconnect 9: wait 33 seconds
reconnect x: etc.
```
在有一千个minions节点时，这意味着：
```
1000/60 = ~16
```
每秒大约有16次连接尝试。 应将这些值更改为与你的环境相匹配的值。 但请记住，它可能会随着时间的推移而增长，而更多的minions接入到管理集群中后可能会再次触发这个问题。

### TOO MANY MINIONS RETURNING AT ONCE
This can also happen during the testing phase, if all minions are addressed at once with

$ salt * disk.usage
it may cause thousands of minions trying to return their data to the Salt Master open port 4506. Also causing a flood of syn-flood if the Master can't handle that many returns at once.

This can be easily avoided with Salt's batch mode:

$ salt * disk.usage -b 50
This will only address 50 minions at once while looping through all addressed minions.

TOO FEW RESOURCES
The masters resources always have to match the environment. There is no way to give good advise without knowing the environment the Master is supposed to run in. But here are some general tuning tips for different situations:

THE MASTER IS CPU BOUND
Salt uses RSA-Key-Pairs on the masters and minions end. Both generate 4096 bit key-pairs on first start. While the key-size for the Master is currently not configurable, the minions keysize can be configured with different key-sizes. For example with a 2048 bit key:

keysize: 2048
With thousands of decryptions, the amount of time that can be saved on the masters end should not be neglected. See here for reference: Pull Request 9235 how much influence the key-size can have.

Downsizing the Salt Master's key is not that important, because the minions do not encrypt as many messages as the Master does.

In installations with large or with complex pillar files, it is possible for the master to exhibit poor performance as a result of having to render many pillar files at once. This exhibit itself in a number of ways, both as high load on the master and on minions which block on waiting for their pillar to be delivered to them.

To reduce pillar rendering times, it is possible to cache pillars on the master. To do this, see the set of master configuration options which are prefixed with pillar_cache.

Note

Caching pillars on the master may introduce security considerations. Be certain to read caveats outlined in the master configuration file to understand how pillar caching may affect a master's ability to protect sensitive data!

THE MASTER IS DISK IO BOUND
By default, the Master saves every Minion's return for every job in its job-cache. The cache can then be used later, to lookup results for previous jobs. The default directory for this is:

cachedir: /var/cache/salt
and then in the /proc directory.

Each job return for every Minion is saved in a single file. Over time this directory can grow quite large, depending on the number of published jobs. The amount of files and directories will scale with the number of jobs published and the retention time defined by

keep_jobs: 24
250 jobs/day * 2000 minions returns = 500,000 files a day
USE AND EXTERNAL JOB CACHE
An external job cache allows for job storage to be placed on an external system, such as a database.

ext_job_cache: this will have the minions store their return data directly into a returner (not sent through the Master)

master_job_cache (New in 2014.7.0): this will make the Master store the job data using a returner (instead of the local job cache on disk).

If a master has many accepted keys, it may take a long time to publish a job because the master much first determine the matching minions and deliver that information back to the waiting client before the job can be published.

To mitigate this, a key cache may be enabled. This will reduce the load on the master to a single file open instead of thousands or tens of thousands.

This cache is updated by the maintanence process, however, which means that minions with keys that are accepted may not be targeted by the master for up to sixty seconds by default.

To enable the master key cache, set key_cache: 'sched' in the master configuration file.

DISABLE THE JOB CACHE
The job cache is a central component of the Salt Master and many aspects of the Salt Master will not function correctly without a running job cache.

Disabling the job cache is STRONGLY DISCOURAGED and should not be done unless the master is being used to execute routines that require no history or reliable feedback!

The job cache can be disabled:

job_cache: False
